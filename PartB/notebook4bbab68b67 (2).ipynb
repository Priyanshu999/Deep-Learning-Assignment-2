{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11449600,"sourceType":"datasetVersion","datasetId":7173509}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:43.933610Z","iopub.execute_input":"2025-04-18T20:40:43.934022Z","iopub.status.idle":"2025-04-18T20:40:47.089336Z","shell.execute_reply.started":"2025-04-18T20:40:43.933992Z","shell.execute_reply":"2025-04-18T20:40:47.088599Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1)\nRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.5.1+cu124)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\nRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\nRequirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.1)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.16)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics>=0.7.0->pytorch-lightning) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.datasets import INaturalist\nimport pytorch_lightning as pl\nimport wandb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\nimport torchvision.models as models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:47.090799Z","iopub.execute_input":"2025-04-18T20:40:47.091070Z","iopub.status.idle":"2025-04-18T20:40:52.716020Z","shell.execute_reply.started":"2025-04-18T20:40:47.091049Z","shell.execute_reply":"2025-04-18T20:40:52.715375Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Function to determine and set the device for computation (CPU/GPU)\ndef set_device():\n    device = \"cpu\"  # Defaulting to CPU\n    if torch.cuda.is_available():  # Checking if GPU is available\n        device = torch.device(\"cuda\")  # Setting device to GPU if available\n    else:\n        device = torch.device(\"cpu\")  # Otherwise, default to CPU\n    return device\n\ndevice = set_device()  # Calling the function to set the device\nprint(\"Currently Using :: \", device)  # Printing the currently used device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.716684Z","iopub.execute_input":"2025-04-18T20:40:52.716898Z","iopub.status.idle":"2025-04-18T20:40:52.741602Z","shell.execute_reply.started":"2025-04-18T20:40:52.716880Z","shell.execute_reply":"2025-04-18T20:40:52.740817Z"}},"outputs":[{"name":"stdout","text":"Currently Using ::  cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install split-folders\nimport splitfolders\n# Adjust the path accordingly\ndata_path = '/kaggle/input/nature-12k/inaturalist_12K/train'  #path where train data to be split is stored\noutput_path=\"train_val\" #path where new split data train+validation should be stored\n\n# This will randomly split data Set `seed` to ensure reproducibility and `group_strategy` to 'equal' for equal representation of classes in validation set\nsplitfolders.ratio(input=data_path, output=output_path, seed=42, ratio=(0.8, 0.2) )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.743119Z","iopub.execute_input":"2025-04-18T20:40:52.743411Z","iopub.status.idle":"2025-04-18T20:40:52.746823Z","shell.execute_reply.started":"2025-04-18T20:40:52.743392Z","shell.execute_reply":"2025-04-18T20:40:52.746258Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\n\ndef configure_loaders(augment_data):\n    # Configuration registry for model parameters\n    config = {\n        'input_size': 224,  # Standard size for pretrained networks\n        'scale_range': (0.08, 1.0),  # Default crop scaling from original paper\n        'norm_mean': [0.485, 0.456, 0.406],  # Imagenet statistics\n        'norm_std': [0.229, 0.224, 0.225],   # Channel-wise normalization\n        'loader_params': {  # Optimized data loading configuration\n            'batch_size': 64,       # Balanced memory/throughput tradeoff\n            'num_workers': 4,       # CPU cores for parallel loading\n            'pin_memory': True,     # Faster GPU transfers\n            'persistent_workers': True  # Maintain worker pools between epochs\n        }\n    }\n\n    # Base vision processing pipeline (essential tensor conversion)\n    def create_base_pipeline():\n        return [\n            # Randomized input sampling for scale invariance\n            transforms.RandomResizedCrop(\n                config['input_size'],\n                scale=config['scale_range']\n            ),\n            # Convert PIL Image to CxHxW torch.Tensor\n            transforms.ToTensor()\n        ]\n\n    # Quality assurance: Validate transform sequence integrity\n    def is_valid_transform(transform_list):\n        \"\"\"Ensure pipeline contains essential preprocessing steps\"\"\"\n        return len(transform_list) > 2  # Verify minimum processing requirements\n\n    # Feature engineering: Augmentation module injection point\n    augmentation_modules = [\n        # Horizontal mirroring for left-right invariance\n        transforms.RandomHorizontalFlip(p=0.5),\n        # Rotation tolerance for viewpoint variation\n        transforms.RandomRotation(degrees=30)\n    ] if str(augment_data).lower() == \"true\" else []\n\n    # Construct processing pipeline with dynamic extensions\n    processing_pipe = create_base_pipeline()\n    # Insert augmentation strategies at optimal position\n    processing_pipe[1:1] = augmentation_modules  # Preserve tensor conversion timing\n\n    # Add normalization after verifying pipeline validity\n    if is_valid_transform(processing_pipe):\n        # Standardization for stable gradient flow\n        processing_pipe.append(transforms.Normalize(\n            config['norm_mean'],\n            config['norm_std']\n        ))\n\n    # Test-time processing with evaluation optimizations\n    test_pipe = transforms.Compose([\n        # Resolution standardization\n        transforms.Resize(256),\n        # Center crop for consistent input sizing\n        transforms.CenterCrop(224),\n        # Type stability enforcement (PIL -> Tensor)\n        # transforms.Lambda(lambda x: x + 0),  # Prevent dtype inconsistencies\n        # Tensor conversion with range preservation\n        transforms.ToTensor(),\n        # Normalization matching training distribution\n        transforms.Normalize(config['norm_mean'], config['norm_std'])\n    ])\n\n    # Dataset routing configuration\n    data_paths = {\n        'train': '/kaggle/working/train_val/train',       # Primary training samples\n        'validation': '/kaggle/working/train_val/val',   # Hyperparameter tuning set\n        'test': '/kaggle/input/nature-12k/inaturalist_12K/val'  # Final evaluation\n    }\n\n    # Initialize datasets with version-controlled transforms\n    train_ds = ImageFolder(\n        data_paths['train'],\n        transforms.Compose(processing_pipe)\n    )\n    val_ds = ImageFolder(data_paths['validation'], test_pipe)\n    test_ds = ImageFolder(data_paths['test'], test_pipe)\n\n    # Data loader factory with performance tuning\n    def create_loader(dataset, shuffle=False):\n        \"\"\"Configure optimized data feeding pipeline\"\"\"\n        return DataLoader(\n            dataset,\n            shuffle=shuffle,\n            **config['loader_params']\n        )\n\n    return (\n        create_loader(train_ds, shuffle=True),  # Training with instance randomization\n        create_loader(val_ds),                   # Validation with deterministic order\n        create_loader(test_ds)                    # Final evaluation protocol\n    )\n\n    # Pipeline verification system (planned for CI/CD integration)\n    def _verify_transforms():\n        \"\"\"Sanity check for transform sequence compatibility\"\"\"\n        return \"Validation passed\" if len(processing_pipe) > 3 else \"Insufficient processing\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.747501Z","iopub.execute_input":"2025-04-18T20:40:52.747736Z","iopub.status.idle":"2025-04-18T20:40:52.760569Z","shell.execute_reply.started":"2025-04-18T20:40:52.747708Z","shell.execute_reply":"2025-04-18T20:40:52.759865Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def freeze_layers(model, options, k):\n    \"\"\"\n    Freeze specified layers of a neural network model.\n\n    Args:\n    - model (torch.nn.Module): The neural network model.\n    - options (str): Specifies which layers to freeze. Options: \"start\", \"middle\", or \"end\".\n    - k (int): Number of layers to freeze. For \"start\" and \"end\" options, k specifies the number of layers from the start or end respectively.\n\n    Raises:\n    - ValueError: If k is not within the valid range.\n\n    Returns:\n    - None\n    \"\"\"\n\n    # Check if k is within the valid range\n    if k < 0 or k >= len(list(model.named_children())):\n        raise ValueError(f\"Invalid value of k. Choose between 0 and {len(list(model.named_children())) - 1}\")\n\n\n# Freeze layers based on the specified option\n\n    # Freeze first k layers\n    if options == \"start\":\n        for layer_num, (name, layer) in enumerate(model.named_children(), 1):\n            if layer_num <= k:\n                for p_name, param in layer.named_parameters():\n                    param.requires_grad = False\n        print(f\"Freezed First {k} Layer\")\n\n\n    # Freeze Middle layers\n    elif options == \"middle\":\n        total_layer = len(list(model.named_children()))\n        middle_layer = total_layer // 2  # Get the index of the middle layer\n        num_layers_to_freeze = k  # Number of layers to freeze around the middle layer\n\n        for layer_num, (name, layer) in enumerate(model.named_children(), 1):\n            if middle_layer - num_layers_to_freeze <= layer_num < middle_layer + num_layers_to_freeze:\n                for p_name, param in layer.named_parameters():\n                    param.requires_grad = False\n\n        start_layer = middle_layer - num_layers_to_freeze\n        end_layer = middle_layer + num_layers_to_freeze\n        print(f\"Freeze middle layers from layer {start_layer} to {end_layer} and Train rest of the layers\")\n\n\n    # Freeze last k layers \n    elif options == \"end\":\n        total_layers = len(list(model.named_children()))\n        start_layer = total_layers - k\n        end_layer = total_layers\n        \n        for layer_num, (name, layer) in enumerate(model.named_children(), 1):\n            if start_layer <= layer_num <= end_layer:\n                for p_name, param in layer.named_parameters():\n                    param.requires_grad = False\n        \n        print(f\"Freeze last {k} layers and Train rest of the layers\")\n\n\n    # Freeze all layers (train only last layer)\n    elif options == \"freeze_all\":\n        total_layers = len(list(model.named_children()))\n        curr_layers = 0\n        for name, layer in model.named_children():\n            if curr_layers < total_layers - 1:\n                for p_name, param in layer.named_parameters():\n                    # print(p_name)\n                    param.requires_grad = False\n            curr_layers += 1\n\n        print(f\"Train only last layer and freeze all other layers\")\n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.761418Z","iopub.execute_input":"2025-04-18T20:40:52.761666Z","iopub.status.idle":"2025-04-18T20:40:52.776113Z","shell.execute_reply.started":"2025-04-18T20:40:52.761649Z","shell.execute_reply":"2025-04-18T20:40:52.775577Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def _activation_registry(activation_name):\n    \"\"\"Non-linear response function selector\"\"\"\n    registry = {\n        \"ReLU\": nn.ReLU(),        # Standard rectification\n        \"GELU\": nn.GELU(),        # Gaussian error linear unit\n        \"SiLU\": nn.SiLU(),        # Sigmoid-weighted linear unit\n        \"Mish\": nn.Mish(),        # Self-regularized non-linearity\n        \"LeakyReLU\": nn.LeakyReLU() # Negative slope preservation\n    }\n\n    # Future-proofing for unknown activations\n    if activation_name not in registry:\n        raise ValueError(f\"Unsupported activation: {activation_name}\")\n\n    return registry[activation_name]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.776913Z","iopub.execute_input":"2025-04-18T20:40:52.777131Z","iopub.status.idle":"2025-04-18T20:40:52.790903Z","shell.execute_reply.started":"2025-04-18T20:40:52.777115Z","shell.execute_reply":"2025-04-18T20:40:52.790353Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train(num_cycles, network, train_loader, val_loader, logging_mode, strategy, k):\n    \"\"\"Orchestrate model training with stability enhancements\"\"\"\n    freeze_layers(network, strategy, k)\n    # Optimization configuration\n    loss_metric = nn.CrossEntropyLoss()\n    optimization_policy = {\n        'lr': 1e-4,\n        'betas': (0.9, 0.999),\n        'grad_clip': 5.0,  # Prevent gradient explosions\n        'enable_amp': False  # Automatic Mixed Precision\n    }\n\n    # Parameter update engine\n    optim = torch.optim.Adam(\n        network.parameters(),\n        lr=optimization_policy['lr'],\n        betas=optimization_policy['betas']\n    )\n\n    # Training state tracking\n    phase_metrics = {\n        'train': {'correct': 0, 'total': 0, 'loss': 0.0},\n        'val': {'correct': 0, 'total': 0, 'loss': 0.0}\n    }\n\n    # Learning rate warmup scheduler (no actual scaling)\n    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n        optim, lr_lambda=lambda epoch: 1.0\n    )\n\n    for cycle in range(num_cycles):\n        # Phase 1: Parameter Update\n        network.train()\n        phase_metrics['train'] = {k: 0 for k in phase_metrics['train']}\n\n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            # Hardware acceleration protocol\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # Forward propagation\n            predictions = network(inputs)\n            batch_loss = loss_metric(predictions, targets)\n\n            # Backward propagation with safety measures\n            optim.zero_grad()\n            batch_loss.backward()\n\n            # Gradient normalization safeguard\n            torch.nn.utils.clip_grad_norm_(\n                network.parameters(),\n                optimization_policy['grad_clip']\n            )\n\n            # Parameter update\n            optim.step()\n\n            # Metric aggregation\n            phase_metrics['train']['loss'] += batch_loss.item()\n            _, predicted_labels = torch.max(predictions, 1)\n            phase_metrics['train']['correct'] += (predicted_labels == targets).sum().item()\n            phase_metrics['train']['total'] += targets.size(0)\n\n            # Progress monitoring\n            if (batch_idx+1) % 25 == 0:\n                print(f'Epoch [{cycle+1}/{num_cycles}], Batch [{batch_idx+1}/{len(train_loader)}]')\n\n        # Phase 1 metrics calculation\n        train_acc = 100.0 * phase_metrics['train']['correct'] / phase_metrics['train']['total']\n        avg_train_loss = phase_metrics['train']['loss'] / len(train_loader)\n        print(f'Epoch {cycle+1}, Train Accuracy: {train_acc:.2f}%, Avg Loss: {avg_train_loss:.4f}')\n\n        # Phase 2: Model Validation\n        network.eval()\n        phase_metrics['val'] = {k: 0 for k in phase_metrics['val']}\n\n        with torch.no_grad():\n            for val_inputs, val_targets in val_loader:\n                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n                val_predictions = network(val_inputs)\n                val_loss = loss_metric(val_predictions, val_targets)\n\n                # Prediction consensus\n                _, val_predicted = torch.max(val_predictions, 1)\n                phase_metrics['val']['correct'] += (val_predicted == val_targets).sum().item()\n                phase_metrics['val']['total'] += val_targets.size(0)\n                phase_metrics['val']['loss'] += val_loss.item()\n\n        # Phase 2 metrics calculation\n        val_acc = 100.0 * phase_metrics['val']['correct'] / phase_metrics['val']['total']\n        avg_val_loss = phase_metrics['val']['loss'] / len(val_loader)\n        print(f'Epoch {cycle+1}, Validation Accuracy: {val_acc:.2f}%, Avg Loss: {avg_val_loss:.4f}')\n\n        # External logging interface\n        if logging_mode == \"wandb\":\n            _log_training_artifacts(\n                cycle+1, avg_train_loss, train_acc, avg_val_loss, val_acc\n            )\n\n    # Final model capability score\n    return val_acc\n\ndef _log_training_artifacts(cycle, train_loss, train_acc, val_loss, val_acc):\n    \"\"\"Record training trajectory for analysis\"\"\"\n    wandb.log({\n        'Epoch': cycle,\n        'Training Loss': train_loss,\n        'Training Accuracy': train_acc,\n        'Validation Loss': val_loss,\n        'Validation Accuracy': val_acc\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.791685Z","iopub.execute_input":"2025-04-18T20:40:52.792043Z","iopub.status.idle":"2025-04-18T20:40:52.807553Z","shell.execute_reply.started":"2025-04-18T20:40:52.792015Z","shell.execute_reply":"2025-04-18T20:40:52.806973Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def load_model(device):\n    model = models.googlenet(pretrained=True)\n    last_layer_in_features = model.fc.in_features\n    model.fc = nn.Linear(last_layer_in_features, 10)\n    model = model.to(device)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.808365Z","iopub.execute_input":"2025-04-18T20:40:52.808658Z","iopub.status.idle":"2025-04-18T20:40:52.821898Z","shell.execute_reply.started":"2025-04-18T20:40:52.808641Z","shell.execute_reply":"2025-04-18T20:40:52.821322Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"model = load_model(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:52.823913Z","iopub.execute_input":"2025-04-18T20:40:52.824117Z","iopub.status.idle":"2025-04-18T20:40:53.155298Z","shell.execute_reply.started":"2025-04-18T20:40:52.824102Z","shell.execute_reply":"2025-04-18T20:40:53.154690Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi',\n           'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.155977Z","iopub.execute_input":"2025-04-18T20:40:53.156166Z","iopub.status.idle":"2025-04-18T20:40:53.160135Z","shell.execute_reply.started":"2025-04-18T20:40:53.156152Z","shell.execute_reply":"2025-04-18T20:40:53.159553Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def test_model(network, data_loader):\n    \"\"\"Execute model evaluation with diagnostic analytics\"\"\"\n    # Evaluation protocol configuration\n    eval_profile = {\n        'loss_function': nn.CrossEntropyLoss(),\n        'sample_capture_interval': 200,  # Diagnostic imaging frequency\n        'precision_mode': 'fp32',         # Evaluation precision\n        'enable_metrics': True            # Comprehensive reporting\n    }\n\n    # Performance tracking\n    performance_stats = {\n        'correct': 0,\n        'total': 0,\n        'loss': 0.0,\n        'diagnostic_images': [],\n        'prediction_records': []\n    }\n\n    # Hardware optimization\n    compute_device = next(network.parameters()).device\n\n    with torch.inference_mode():\n        sample_counter = 0\n        for batch_inputs, batch_labels in data_loader:\n            # Data standardization protocol\n            batch_inputs = batch_inputs.to(compute_device)\n            batch_labels = batch_labels.to(compute_device)\n\n            # Model inference\n            predictions = network(batch_inputs)\n\n            # Loss computation\n            batch_loss = eval_profile['loss_function'](predictions, batch_labels)\n            performance_stats['loss'] += batch_loss.item()\n\n            # Prediction analysis\n            _, predicted_classes = torch.max(predictions, 1)\n            performance_stats['correct'] += (predicted_classes == batch_labels).sum().item()\n            performance_stats['total'] += batch_labels.size(0)\n\n            # Diagnostic image capture\n            if eval_profile['enable_metrics']:\n                for idx in range(batch_inputs.size(0)):\n                    sample_counter += 1\n                    if sample_counter % eval_profile['sample_capture_interval'] in (1, 2, 3):\n                        if sample_counter % eval_profile['sample_capture_interval'] in (1, 2, 3):\n                            performance_stats['diagnostic_images'].append(batch_inputs[idx])\n                            performance_stats['prediction_records'].append((batch_labels[idx].item(), predicted_classes[idx].item()))\n                            print(f'Class Verification: Actual: {classes[batch_labels[idx]]}, Predicted: {classes[predicted_classes[idx]]}')\n\n\n        # Final metric computation\n        accuracy = 100.0 * performance_stats['correct'] / performance_stats['total']\n        avg_loss = performance_stats['loss'] / len(data_loader)\n\n        # Result certification\n        print(f'Model Diagnostics :: Accuracy: {accuracy:.2f}% | Loss: {avg_loss:.4f}')\n        print(f'Total Samples Analyzed: {performance_stats[\"total\"]}')\n\n    return performance_stats['diagnostic_images'], performance_stats['prediction_records']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.160817Z","iopub.execute_input":"2025-04-18T20:40:53.161048Z","iopub.status.idle":"2025-04-18T20:40:53.170960Z","shell.execute_reply.started":"2025-04-18T20:40:53.161033Z","shell.execute_reply":"2025-04-18T20:40:53.170252Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# test_images , test_labels = test_model(model , test_dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.171677Z","iopub.execute_input":"2025-04-18T20:40:53.171859Z","iopub.status.idle":"2025-04-18T20:40:53.184543Z","shell.execute_reply.started":"2025-04-18T20:40:53.171845Z","shell.execute_reply":"2025-04-18T20:40:53.183908Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import wandb\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom io import BytesIO\nfrom PIL import Image\n\nsns.set_style(\"white\")\n\ndef display_images_with_predictions(test_images, test_labels, classes, num_rows=10, num_cols=3, log_to_wandb=False):\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 4, num_rows * 3))\n    axes = axes.flatten()\n    total = num_rows * num_cols\n\n    for i in range(total):\n        ax = axes[i]\n        img = np.transpose(test_images[i].cpu().numpy(), (1, 2, 0))\n        img_min, img_max = img.min(), img.max()\n        img = (img - img_min) / (img_max - img_min + 1e-5)\n\n        ax.imshow(img)\n        ax.axis('off')\n\n        true_label = test_labels[i][0]\n        pred_label = test_labels[i][1]\n        correct = (true_label == pred_label)\n\n        emoji = \"✓\" if correct else \"✗\"\n        label_color = 'green' if correct else 'red'\n\n        ax.set_title(f\"{emoji} True: {classes[true_label]}\\nPred: {classes[pred_label]}\",\n                     fontsize=9, color=label_color, loc='center', pad=10)\n\n        for spine in ax.spines.values():\n            spine.set_linewidth(1.5)\n            spine.set_color(label_color)\n            spine.set_linestyle('--')\n\n    plt.subplots_adjust(hspace=0.6, wspace=0.2)\n    plt.tight_layout()\n\n\n    if log_to_wandb:\n        buf = BytesIO()\n        plt.savefig(buf, format='png')\n        buf.seek(0)\n        image = Image.open(buf)  # Convert BytesIO to PIL Image\n        wandb.log({\"Predictions\": wandb.Image(image)})\n        buf.close()\n        plt.close(fig)\n        plt.show()\n\n    else:\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.185214Z","iopub.execute_input":"2025-04-18T20:40:53.185481Z","iopub.status.idle":"2025-04-18T20:40:53.488542Z","shell.execute_reply.started":"2025-04-18T20:40:53.185459Z","shell.execute_reply":"2025-04-18T20:40:53.487937Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = load_model(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.489262Z","iopub.execute_input":"2025-04-18T20:40:53.489624Z","iopub.status.idle":"2025-04-18T20:40:53.689461Z","shell.execute_reply.started":"2025-04-18T20:40:53.489607Z","shell.execute_reply":"2025-04-18T20:40:53.688656Z"}},"outputs":[{"name":"stdout","text":"GoogLeNet(\n  (conv1): BasicConv2d(\n    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (conv2): BasicConv2d(\n    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv3): BasicConv2d(\n    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception3a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception3b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception4a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4c): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4d): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception4e): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n  (inception5a): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception5b): Inception(\n    (branch1): BasicConv2d(\n      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): BasicConv2d(\n        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicConv2d(\n        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n      (1): BasicConv2d(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (aux1): None\n  (aux2): None\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc): Linear(in_features=1024, out_features=10, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_loader , val_loader , test_loader = configure_loaders(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.690157Z","iopub.execute_input":"2025-04-18T20:40:53.690400Z","iopub.status.idle":"2025-04-18T20:40:53.744556Z","shell.execute_reply.started":"2025-04-18T20:40:53.690383Z","shell.execute_reply":"2025-04-18T20:40:53.743812Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"epochs=6\nstrategy='start'\nk=5\ntrain(epochs,model,train_loader,val_loader,\"print_on\", strategy, k)\ntest_images, test_labels = test_model(model, test_loader)\ndisplay_images_with_predictions(test_images, test_labels, classes, log_to_wandb=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:40:53.745408Z","iopub.execute_input":"2025-04-18T20:40:53.745606Z","execution_failed":"2025-04-18T21:19:48.761Z"}},"outputs":[{"name":"stdout","text":"Freezed First 5 Layer\nEpoch [1/6], Batch [25/125]\nEpoch [1/6], Batch [50/125]\nEpoch [1/6], Batch [75/125]\nEpoch [1/6], Batch [100/125]\nEpoch [1/6], Batch [125/125]\nEpoch 1, Train Accuracy: 53.39%, Avg Loss: 1.5109\nEpoch 1, Validation Accuracy: 70.15%, Avg Loss: 0.9186\nEpoch [2/6], Batch [25/125]\nEpoch [2/6], Batch [50/125]\nEpoch [2/6], Batch [75/125]\nEpoch [2/6], Batch [100/125]\nEpoch [2/6], Batch [125/125]\nEpoch 2, Train Accuracy: 67.55%, Avg Loss: 0.9920\nEpoch 2, Validation Accuracy: 74.95%, Avg Loss: 0.7647\nEpoch [3/6], Batch [25/125]\nEpoch [3/6], Batch [50/125]\nEpoch [3/6], Batch [75/125]\nEpoch [3/6], Batch [100/125]\nEpoch [3/6], Batch [125/125]\nEpoch 3, Train Accuracy: 71.28%, Avg Loss: 0.8637\nEpoch 3, Validation Accuracy: 77.20%, Avg Loss: 0.6784\nEpoch [4/6], Batch [25/125]\nEpoch [4/6], Batch [50/125]\nEpoch [4/6], Batch [75/125]\nEpoch [4/6], Batch [100/125]\nEpoch [4/6], Batch [125/125]\nEpoch 4, Train Accuracy: 73.85%, Avg Loss: 0.7832\nEpoch 4, Validation Accuracy: 77.80%, Avg Loss: 0.6796\nEpoch [5/6], Batch [25/125]\nEpoch [5/6], Batch [50/125]\nEpoch [5/6], Batch [75/125]\nEpoch [5/6], Batch [100/125]\nEpoch [5/6], Batch [125/125]\nEpoch 5, Train Accuracy: 76.21%, Avg Loss: 0.7219\nEpoch 5, Validation Accuracy: 78.75%, Avg Loss: 0.6465\nEpoch [6/6], Batch [25/125]\nEpoch [6/6], Batch [50/125]\nEpoch [6/6], Batch [75/125]\nEpoch [6/6], Batch [100/125]\nEpoch [6/6], Batch [125/125]\nEpoch 6, Train Accuracy: 76.87%, Avg Loss: 0.6980\nEpoch 6, Validation Accuracy: 79.00%, Avg Loss: 0.6427\nClass Verification: Actual: Amphibia, Predicted: Amphibia\nClass Verification: Actual: Amphibia, Predicted: Amphibia\nClass Verification: Actual: Amphibia, Predicted: Mollusca\nClass Verification: Actual: Animalia, Predicted: Mollusca\nClass Verification: Actual: Animalia, Predicted: Mollusca\nClass Verification: Actual: Animalia, Predicted: Amphibia\nClass Verification: Actual: Arachnida, Predicted: Arachnida\nClass Verification: Actual: Arachnida, Predicted: Arachnida\nClass Verification: Actual: Arachnida, Predicted: Arachnida\nClass Verification: Actual: Aves, Predicted: Aves\nClass Verification: Actual: Aves, Predicted: Aves\nClass Verification: Actual: Aves, Predicted: Aves\nClass Verification: Actual: Fungi, Predicted: Fungi\nClass Verification: Actual: Fungi, Predicted: Fungi\nClass Verification: Actual: Fungi, Predicted: Fungi\nClass Verification: Actual: Insecta, Predicted: Insecta\nClass Verification: Actual: Insecta, Predicted: Insecta\nClass Verification: Actual: Insecta, Predicted: Insecta\nClass Verification: Actual: Mammalia, Predicted: Mammalia\nClass Verification: Actual: Mammalia, Predicted: Mammalia\nClass Verification: Actual: Mammalia, Predicted: Mammalia\nClass Verification: Actual: Mollusca, Predicted: Amphibia\nClass Verification: Actual: Mollusca, Predicted: Mollusca\nClass Verification: Actual: Mollusca, Predicted: Animalia\nClass Verification: Actual: Plantae, Predicted: Plantae\nClass Verification: Actual: Plantae, Predicted: Plantae\nClass Verification: Actual: Plantae, Predicted: Mammalia\nClass Verification: Actual: Reptilia, Predicted: Reptilia\nClass Verification: Actual: Reptilia, Predicted: Reptilia\nClass Verification: Actual: Reptilia, Predicted: Reptilia\nModel Diagnostics :: Accuracy: 80.15% | Loss: 0.6018\nTotal Samples Analyzed: 2000\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model = load_model(device)\n# print(model)\ntrain_loader , val_loader , test_loader = configure_loaders(True)\nepochs=\nstrategy='middle'\nk=5\ntrain(epochs,model,train_loader,val_loader,\"print_on\", strategy, k)\ntest_images, test_labels = test_model(model, test_loader)\ndisplay_images_with_predictions(test_images, test_labels, classes, log_to_wandb=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T21:19:48.761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = load_model(device)\n# print(model)\ntrain_loader , val_loader , test_loader = configure_loaders(True)\nepochs=5\nstrategy='end'\nk=5\ntrain(epochs,model,train_loader,val_loader,\"print_on\", strategy, k)\ntest_images, test_labels = test_model(model, test_loader)\ndisplay_images_with_predictions(test_images, test_labels, classes, log_to_wandb=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T21:19:48.761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = load_model(device)\n# print(model)\ntrain_loader , val_loader , test_loader = configure_loaders(True)\nepochs=5\nstrategy='freeze_all'\nk=5\ntrain(epochs,model,train_loader,val_loader,\"print_on\", strategy, k)\ntest_images, test_labels = test_model(model, test_loader)\ndisplay_images_with_predictions(test_images, test_labels, classes, log_to_wandb=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T21:19:48.762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}