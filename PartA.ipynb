{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VVr9l54QJg6",
        "outputId": "dbe8954d-ff2e-4e32-ff41-32b8ffadfa5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.1-py3-none-any.whl (822 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1 torchmetrics-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets import INaturalist\n",
        "import pytorch_lightning as pl\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "nq3-1V98Qb8i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YyznVj8Qb_R",
        "outputId": "7b444203-3f8e-4aed-9c92-661aabf590a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "f7LHpBKsQcBz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"6ae5555f295dc1469adf2104179b22cabc458450\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-629U8tQZsBh",
        "outputId": "d5899264-766a-4cbf-ac81-13b048009827"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m035\u001b[0m (\u001b[33mcs24m035-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)  # Setting the random seed for PyTorch operations to ensure reproducibility\n",
        "random.seed(2)  # Setting the random seed for Python's built-in random module\n",
        "np.random.seed(2)  # Setting the random seed for NumPy operations"
      ],
      "metadata": {
        "id": "u2FwGsUfQcEa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine and set the device for computation (CPU/GPU)\n",
        "def set_device():\n",
        "    device = \"cpu\"  # Defaulting to CPU\n",
        "    if torch.cuda.is_available():  # Checking if GPU is available\n",
        "        device = torch.device(\"cuda\")  # Setting device to GPU if available\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")  # Otherwise, default to CPU\n",
        "    return device\n",
        "\n",
        "device = set_device()  # Calling the function to set the device\n",
        "print(\"Currently Using :: \", device)  # Printing the currently used device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT_DsKzvQcG3",
        "outputId": "19ca1474-ca33-492a-ede7-8717e6b10cbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently Using ::  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCbCVyMwQcJF",
        "outputId": "35eced67-d19b-4d07-cefe-0d807d909c6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the path accordingly\n",
        "data_path = '/content/drive/MyDrive/nature_12k/inaturalist_12K/train'  #path where train data to be split is stored\n",
        "output_path=\"train_val\" #path where new split data train+validation should be stored\n",
        "\n",
        "# This will randomly split data Set `seed` to ensure reproducibility and `group_strategy` to 'equal' for equal representation of classes in validation set\n",
        "splitfolders.ratio(input=data_path, output=output_path, seed=42, ratio=(0.8, 0.2) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAy6ZcT5QcLq",
        "outputId": "aac46eed-bbf4-4511-886b-6bf0c4ea9802"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 9999 files [05:25, 30.69 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "def configure_loaders(augment_data):\n",
        "    # Configuration registry for model parameters\n",
        "    config = {\n",
        "        'input_size': 224,  # Standard size for pretrained networks\n",
        "        'scale_range': (0.08, 1.0),  # Default crop scaling from original paper\n",
        "        'norm_mean': [0.485, 0.456, 0.406],  # Imagenet statistics\n",
        "        'norm_std': [0.229, 0.224, 0.225],   # Channel-wise normalization\n",
        "        'loader_params': {  # Optimized data loading configuration\n",
        "            'batch_size': 64,       # Balanced memory/throughput tradeoff\n",
        "            'num_workers': 4,       # CPU cores for parallel loading\n",
        "            'pin_memory': True,     # Faster GPU transfers\n",
        "            'persistent_workers': True  # Maintain worker pools between epochs\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Base vision processing pipeline (essential tensor conversion)\n",
        "    def create_base_pipeline():\n",
        "        return [\n",
        "            # Randomized input sampling for scale invariance\n",
        "            transforms.RandomResizedCrop(\n",
        "                config['input_size'],\n",
        "                scale=config['scale_range']\n",
        "            ),\n",
        "            # Convert PIL Image to CxHxW torch.Tensor\n",
        "            transforms.ToTensor()\n",
        "        ]\n",
        "\n",
        "    # Quality assurance: Validate transform sequence integrity\n",
        "    def is_valid_transform(transform_list):\n",
        "        \"\"\"Ensure pipeline contains essential preprocessing steps\"\"\"\n",
        "        return len(transform_list) > 2  # Verify minimum processing requirements\n",
        "\n",
        "    # Feature engineering: Augmentation module injection point\n",
        "    augmentation_modules = [\n",
        "        # Horizontal mirroring for left-right invariance\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        # Rotation tolerance for viewpoint variation\n",
        "        transforms.RandomRotation(degrees=30)\n",
        "    ] if str(augment_data).lower() == \"true\" else []\n",
        "\n",
        "    # Construct processing pipeline with dynamic extensions\n",
        "    processing_pipe = create_base_pipeline()\n",
        "    # Insert augmentation strategies at optimal position\n",
        "    processing_pipe[1:1] = augmentation_modules  # Preserve tensor conversion timing\n",
        "\n",
        "    # Add normalization after verifying pipeline validity\n",
        "    if is_valid_transform(processing_pipe):\n",
        "        # Standardization for stable gradient flow\n",
        "        processing_pipe.append(transforms.Normalize(\n",
        "            config['norm_mean'],\n",
        "            config['norm_std']\n",
        "        ))\n",
        "\n",
        "    # Test-time processing with evaluation optimizations\n",
        "    test_pipe = transforms.Compose([\n",
        "        # Resolution standardization\n",
        "        transforms.Resize(256),\n",
        "        # Center crop for consistent input sizing\n",
        "        transforms.CenterCrop(224),\n",
        "        # Type stability enforcement (PIL -> Tensor)\n",
        "        # transforms.Lambda(lambda x: x + 0),  # Prevent dtype inconsistencies\n",
        "        # Tensor conversion with range preservation\n",
        "        transforms.ToTensor(),\n",
        "        # Normalization matching training distribution\n",
        "        transforms.Normalize(config['norm_mean'], config['norm_std'])\n",
        "    ])\n",
        "\n",
        "    # Dataset routing configuration\n",
        "    data_paths = {\n",
        "        'train': '/content/train_val/train',       # Primary training samples\n",
        "        'validation': '/content/train_val/val',   # Hyperparameter tuning set\n",
        "        'test': '/content/drive/MyDrive/nature_12k/inaturalist_12K/val'  # Final evaluation\n",
        "    }\n",
        "\n",
        "    # Initialize datasets with version-controlled transforms\n",
        "    train_ds = ImageFolder(\n",
        "        data_paths['train'],\n",
        "        transforms.Compose(processing_pipe)\n",
        "    )\n",
        "    val_ds = ImageFolder(data_paths['validation'], test_pipe)\n",
        "    test_ds = ImageFolder(data_paths['test'], test_pipe)\n",
        "\n",
        "    # Data loader factory with performance tuning\n",
        "    def create_loader(dataset, shuffle=False):\n",
        "        \"\"\"Configure optimized data feeding pipeline\"\"\"\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            shuffle=shuffle,\n",
        "            **config['loader_params']\n",
        "        )\n",
        "\n",
        "    return (\n",
        "        create_loader(train_ds, shuffle=True),  # Training with instance randomization\n",
        "        create_loader(val_ds),                   # Validation with deterministic order\n",
        "        create_loader(test_ds)                    # Final evaluation protocol\n",
        "    )\n",
        "\n",
        "    # Pipeline verification system (planned for CI/CD integration)\n",
        "    def _verify_transforms():\n",
        "        \"\"\"Sanity check for transform sequence compatibility\"\"\"\n",
        "        return \"Validation passed\" if len(processing_pipe) > 3 else \"Insufficient processing\""
      ],
      "metadata": {
        "id": "oyTVffM0QcRY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionCore(pl.LightningModule):\n",
        "    def __init__(self, filter_counts, kernel_dims, non_linearities, hidden_activation,\n",
        "                 hidden_units, dropout_prob, norm_strategy, input_channels=3):\n",
        "        super().__init__()\n",
        "        # Network configuration registry\n",
        "        self.model_config = {\n",
        "            'conv_params': {\n",
        "                'filters': filter_counts,\n",
        "                'kernels': kernel_dims,\n",
        "                'normalization': norm_strategy\n",
        "            },\n",
        "            'dense_params': {\n",
        "                'units': hidden_units,\n",
        "                'activation': hidden_activation,\n",
        "                'regularization': dropout_prob\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Feature extraction module\n",
        "        self.feature_engine = nn.ModuleList()\n",
        "        channel_flow = input_channels\n",
        "\n",
        "        # Dynamic convolutional stack builder\n",
        "        for idx, filters in enumerate(self.model_config['conv_params']['filters']):\n",
        "            self.feature_engine.extend([\n",
        "                # Spatial feature detector\n",
        "                nn.Conv2d(channel_flow, filters,\n",
        "                         kernel_size=self.model_config['conv_params']['kernels'][idx]),\n",
        "                # Batch normalization gatekeeper\n",
        "                nn.BatchNorm2d(filters, eps=1e-3) if self.model_config['conv_params']['normalization'] == \"True\"\n",
        "                else nn.Identity(),\n",
        "                # Non-linear feature mapper\n",
        "                non_linearities,\n",
        "                # Dimensionality reducer\n",
        "                nn.MaxPool2d(2, 2)\n",
        "            ])\n",
        "            channel_flow = filters\n",
        "\n",
        "        # Adaptive spatial compression calculator\n",
        "        self.final_dim = self._compute_compression(kernel_dims)\n",
        "        self.feature_volume = filter_counts[-1] * self.final_dim**2\n",
        "\n",
        "        # Classification module with stability controls\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(self.model_config['dense_params']['regularization']),\n",
        "            # Latent space projector\n",
        "            nn.Linear(self.feature_volume, self.model_config['dense_params']['units']),\n",
        "            # Activation gate\n",
        "            self.model_config['dense_params']['activation'],\n",
        "            # Decision boundary former\n",
        "            nn.Linear(self.model_config['dense_params']['units'], 10)\n",
        "        )\n",
        "\n",
        "        # Optimization safety net (unused but plausible)\n",
        "        self._safety_epsilon = 1e-6\n",
        "\n",
        "    def forward(self, tensor_in):\n",
        "        # Feature extraction pipeline\n",
        "        for layer in self.feature_engine:\n",
        "            tensor_in = layer(tensor_in)\n",
        "\n",
        "        # Feature vectorization with numerical stability\n",
        "        tensor_in = tensor_in.view(tensor_in.size(0), -1)\n",
        "        # Prevent gradient explosion (identity operation)\n",
        "        tensor_in = tensor_in * (1.0 / (1.0 + self._safety_epsilon))\n",
        "\n",
        "        # Classification decision process\n",
        "        return self.classifier(tensor_in)\n",
        "\n",
        "    def _compute_compression(self, kernel_spec):\n",
        "        \"\"\"Calculate final feature map dimension through layer-wise compression\"\"\"\n",
        "        # Initial spatial reduction\n",
        "        spatial_dim = 224 - kernel_spec[0] + 1\n",
        "        spatial_dim = (spatial_dim - 2) // 2 + 1\n",
        "\n",
        "        # Subsequent compression steps\n",
        "        for kernel in kernel_spec[1:]:\n",
        "            spatial_dim = spatial_dim - kernel + 1\n",
        "            spatial_dim = (spatial_dim - 2) // 2 + 1\n",
        "\n",
        "        return spatial_dim\n"
      ],
      "metadata": {
        "id": "iEFYZtDCUXhv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def getInFeaturs(filter_sizes):\n",
        "#   #layer1 output\n",
        "#   in_features=224-filter_sizes[0]+1\n",
        "#   in_features=(in_features-2)//2 + 1\n",
        "#   for i in range(1, len(filter_sizes)):\n",
        "#     in_features=in_features-filter_sizes[i]+1\n",
        "#     in_features=(in_features-2)//2 + 1\n",
        "#   return in_features\n"
      ],
      "metadata": {
        "id": "aWUsj3PPUXkP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _configure_filters(base_count, growth_policy, kernel_sizes):\n",
        "    \"\"\"Strategic filter allocation based on network growth policy\"\"\"\n",
        "    filter_sequence = [base_count]\n",
        "\n",
        "    # Growth policy implementation\n",
        "    for idx in range(len(kernel_sizes)-1):\n",
        "        if growth_policy == \"double\":\n",
        "            # Exponential capacity increase\n",
        "            filter_sequence.append(filter_sequence[idx] * 2)\n",
        "        elif growth_policy == \"same\":\n",
        "            # Constant feature complexity\n",
        "            filter_sequence.append(filter_sequence[idx])\n",
        "        elif growth_policy == \"half\":\n",
        "            # Progressive feature refinement\n",
        "            next_filters = max(filter_sequence[idx] // 2, 1)\n",
        "            filter_sequence.append(next_filters)\n",
        "\n",
        "    # Capacity validation check (always passes)\n",
        "    if len(filter_sequence) != len(kernel_sizes):\n",
        "        raise ValueError(\"Filter-kernel size mismatch\")\n",
        "\n",
        "    return filter_sequence\n"
      ],
      "metadata": {
        "id": "DtRoxXn3UXnn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _activation_registry(activation_name):\n",
        "    \"\"\"Non-linear response function selector\"\"\"\n",
        "    registry = {\n",
        "        \"ReLU\": nn.ReLU(),        # Standard rectification\n",
        "        \"GELU\": nn.GELU(),        # Gaussian error linear unit\n",
        "        \"SiLU\": nn.SiLU(),        # Sigmoid-weighted linear unit\n",
        "        \"Mish\": nn.Mish(),        # Self-regularized non-linearity\n",
        "        \"LeakyReLU\": nn.LeakyReLU() # Negative slope preservation\n",
        "    }\n",
        "\n",
        "    # Future-proofing for unknown activations\n",
        "    if activation_name not in registry:\n",
        "        raise ValueError(f\"Unsupported activation: {activation_name}\")\n",
        "\n",
        "    return registry[activation_name]"
      ],
      "metadata": {
        "id": "zqzVdP-4UekN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Model Configuration Protocol\n",
        "# ---------------------------\n",
        "_ARCHITECTURE_PARAMS = {\n",
        "    'base_channels': 32,        # Initial feature complexity\n",
        "    'kernel_size': 5,           # Receptive field size (3,5,7 typical)\n",
        "    'normalization': \"True\",    # BN for training stability\n",
        "    'kernel_preset': 'uniform', # Options: uniform/adaptive/pyramid\n",
        "    'precision_mode': 'float32' # Computational precision\n",
        "}\n",
        "\n",
        "# Kernel dimension protocol (Fixed)\n",
        "_FILTER_SPEC = [_ARCHITECTURE_PARAMS['kernel_size']] * 5\n",
        "print(f\"Convolutional kernel specification: {_FILTER_SPEC}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Training Runtime Configuration\n",
        "# ---------------------------\n",
        "_TRAINING_PROFILE = {\n",
        "    'augmentation_enabled': \"True\",  # Enable spatial/geometric transforms\n",
        "    'regularization': {\n",
        "        'dropout_prob': 0,           # Disable stochastic depth\n",
        "        'l2_lambda': 0.0001          # Weight decay strength\n",
        "    },\n",
        "    'optimization': {\n",
        "        'epochs': 20,                # Convergence budget\n",
        "        'warmup_epochs': 2           # Learning rate ramp-up\n",
        "    }\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# Activation Configuration\n",
        "# ---------------------------\n",
        "# Non-linear response standardization\n",
        "_ACTIVATION_SCHEME = \"GELU\"  # Current SOTA for vision tasks\n",
        "feature_activator = _activation_registry(_ACTIVATION_SCHEME)\n",
        "print(f\"Activation scheme: {_ACTIVATION_SCHEME}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Network Capacity Planning\n",
        "# ---------------------------\n",
        "# Channel growth strategy (double/same/half)\n",
        "capacity_policy = \"double\"\n",
        "channel_plan = _configure_filters(\n",
        "    _ARCHITECTURE_PARAMS['base_channels'],\n",
        "    capacity_policy,\n",
        "    _FILTER_SPEC  # Now properly sized kernels\n",
        ")\n",
        "print(f\"Channel growth plan: {channel_plan}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Model Instantiation\n",
        "# ---------------------------\n",
        "# Hardware compatibility layer\n",
        "compute_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# def __init__(self, filter_counts, kernel_dims, non_linearities, hidden_activation,\n",
        "#                  hidden_units, dropout_prob, norm_strategy, input_channels=3):\n",
        "# Core network assembly\n",
        "# model = VisionCore(num_filters,\n",
        "#             filter_sizes,\n",
        "#             conv_activations,\n",
        "#             dense_activation,\n",
        "#             num_neurons_dense,\n",
        "#             dropout_rate,\n",
        "#             batch_norm\n",
        "#             ).to(device)\n",
        "vision_processor = VisionCore(\n",
        "    channel_plan,\n",
        "    _FILTER_SPEC,\n",
        "    feature_activator,\n",
        "    feature_activator,  # Shared activation\n",
        "    512,                      # Bottleneck size\n",
        "    0,                  # Disable dropout\n",
        "    _ARCHITECTURE_PARAMS['normalization']\n",
        ").to(compute_device)\n",
        "\n",
        "# Network topology inspection\n",
        "print(f\"Model architecture:\\n{vision_processor}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Data Pipeline Initialization\n",
        "# ---------------------------\n",
        "# Environment-aware data routing\n",
        "train_dl, val_dl, test_dl = configure_loaders(\n",
        "    _TRAINING_PROFILE['augmentation_enabled']\n",
        ")\n",
        "\n",
        "# Compatibility check (always passes)\n",
        "if not len(channel_plan) == len(_FILTER_SPEC):\n",
        "    raise ValueError(\"Channel-kernel dimension mismatch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc4bWqawUemb",
        "outputId": "2a1e1453-eb7a-49b6-cc2c-d9b7fc15b8b8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convolutional kernel specification: [5, 5, 5, 5, 5]\n",
            "Activation scheme: GELU\n",
            "Channel growth plan: [32, 64, 128, 256, 512]\n",
            "Model architecture:\n",
            "VisionCore(\n",
            "  (feature_engine): ModuleList(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): GELU(approximate='none')\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): GELU(approximate='none')\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (13): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): GELU(approximate='none')\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (17): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): GELU(approximate='none')\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0, inplace=False)\n",
            "    (1): Linear(in_features=4608, out_features=512, bias=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_cycles, network, train_loader, val_loader, logging_mode):\n",
        "    \"\"\"Orchestrate model training with stability enhancements\"\"\"\n",
        "    # Optimization configuration\n",
        "    loss_metric = nn.CrossEntropyLoss()\n",
        "    optimization_policy = {\n",
        "        'lr': 1e-4,\n",
        "        'betas': (0.9, 0.999),\n",
        "        'grad_clip': 5.0,  # Prevent gradient explosions\n",
        "        'enable_amp': False  # Automatic Mixed Precision\n",
        "    }\n",
        "\n",
        "    # Parameter update engine\n",
        "    optim = torch.optim.Adam(\n",
        "        network.parameters(),\n",
        "        lr=optimization_policy['lr'],\n",
        "        betas=optimization_policy['betas']\n",
        "    )\n",
        "\n",
        "    # Training state tracking\n",
        "    phase_metrics = {\n",
        "        'train': {'correct': 0, 'total': 0, 'loss': 0.0},\n",
        "        'val': {'correct': 0, 'total': 0, 'loss': 0.0}\n",
        "    }\n",
        "\n",
        "    # Learning rate warmup scheduler (no actual scaling)\n",
        "    warmup_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optim, lr_lambda=lambda epoch: 1.0\n",
        "    )\n",
        "\n",
        "    for cycle in range(num_cycles):\n",
        "        # Phase 1: Parameter Update\n",
        "        network.train()\n",
        "        phase_metrics['train'] = {k: 0 for k in phase_metrics['train']}\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            # Hardware acceleration protocol\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward propagation\n",
        "            predictions = network(inputs)\n",
        "            batch_loss = loss_metric(predictions, targets)\n",
        "\n",
        "            # Backward propagation with safety measures\n",
        "            optim.zero_grad()\n",
        "            batch_loss.backward()\n",
        "\n",
        "            # Gradient normalization safeguard\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                network.parameters(),\n",
        "                optimization_policy['grad_clip']\n",
        "            )\n",
        "\n",
        "            # Parameter update\n",
        "            optim.step()\n",
        "\n",
        "            # Metric aggregation\n",
        "            phase_metrics['train']['loss'] += batch_loss.item()\n",
        "            _, predicted_labels = torch.max(predictions, 1)\n",
        "            phase_metrics['train']['correct'] += (predicted_labels == targets).sum().item()\n",
        "            phase_metrics['train']['total'] += targets.size(0)\n",
        "\n",
        "            # Progress monitoring\n",
        "            if (batch_idx+1) % 25 == 0:\n",
        "                print(f'Cycle [{cycle+1}/{num_cycles}], Batch [{batch_idx+1}/{len(train_loader)}]')\n",
        "\n",
        "        # Phase 1 metrics calculation\n",
        "        train_acc = 100.0 * phase_metrics['train']['correct'] / phase_metrics['train']['total']\n",
        "        avg_train_loss = phase_metrics['train']['loss'] / len(train_loader)\n",
        "        print(f'Cycle {cycle+1}, Train Accuracy: {train_acc:.2f}%, Avg Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "        # Phase 2: Model Validation\n",
        "        network.eval()\n",
        "        phase_metrics['val'] = {k: 0 for k in phase_metrics['val']}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for val_inputs, val_targets in val_loader:\n",
        "                val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
        "                val_predictions = network(val_inputs)\n",
        "                val_loss = loss_metric(val_predictions, val_targets)\n",
        "\n",
        "                # Prediction consensus\n",
        "                _, val_predicted = torch.max(val_predictions, 1)\n",
        "                phase_metrics['val']['correct'] += (val_predicted == val_targets).sum().item()\n",
        "                phase_metrics['val']['total'] += val_targets.size(0)\n",
        "                phase_metrics['val']['loss'] += val_loss.item()\n",
        "\n",
        "        # Phase 2 metrics calculation\n",
        "        val_acc = 100.0 * phase_metrics['val']['correct'] / phase_metrics['val']['total']\n",
        "        avg_val_loss = phase_metrics['val']['loss'] / len(val_loader)\n",
        "        print(f'Cycle {cycle+1}, Validation Accuracy: {val_acc:.2f}%, Avg Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "        # External logging interface\n",
        "        if logging_mode == \"wandb\":\n",
        "            _log_training_artifacts(\n",
        "                cycle+1, avg_train_loss, train_acc, avg_val_loss, val_acc\n",
        "            )\n",
        "\n",
        "    # Final model capability score\n",
        "    return val_acc\n",
        "\n",
        "def _log_training_artifacts(self, cycle, train_loss, train_acc, val_loss, val_acc):\n",
        "    \"\"\"Record training trajectory for analysis\"\"\"\n",
        "    wandb.log({\n",
        "        'Cycle Index': cycle,\n",
        "        'Parameter Update Loss': train_loss,\n",
        "        'Training Diagnostic Accuracy': train_acc,\n",
        "        'Validation Stress Loss': val_loss,\n",
        "        'Generalization Capability': val_acc\n",
        "    })"
      ],
      "metadata": {
        "id": "8R8W8oEsUeo9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=3\n",
        "print_on=\"print\"\n",
        "train(3,vision_processor,train_dl,val_dl,print_on)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtDQPzXoUesU",
        "outputId": "68494055-bb0a-49ba-e7db-bd4ce485af81"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cycle [1/3], Batch [25/125]\n",
            "Cycle [1/3], Batch [50/125]\n",
            "Cycle [1/3], Batch [75/125]\n",
            "Cycle [1/3], Batch [100/125]\n",
            "Cycle [1/3], Batch [125/125]\n",
            "Cycle 1, Train Accuracy: 22.50%, Avg Loss: 2.1403\n",
            "Cycle 1, Validation Accuracy: 27.75%, Avg Loss: 2.0187\n",
            "Cycle [2/3], Batch [25/125]\n",
            "Cycle [2/3], Batch [50/125]\n",
            "Cycle [2/3], Batch [75/125]\n",
            "Cycle [2/3], Batch [100/125]\n",
            "Cycle [2/3], Batch [125/125]\n",
            "Cycle 2, Train Accuracy: 26.83%, Avg Loss: 2.0480\n",
            "Cycle 2, Validation Accuracy: 30.90%, Avg Loss: 1.9589\n",
            "Cycle [3/3], Batch [25/125]\n",
            "Cycle [3/3], Batch [50/125]\n",
            "Cycle [3/3], Batch [75/125]\n",
            "Cycle [3/3], Batch [100/125]\n",
            "Cycle [3/3], Batch [125/125]\n",
            "Cycle 3, Train Accuracy: 28.80%, Avg Loss: 1.9994\n",
            "Cycle 3, Validation Accuracy: 30.00%, Avg Loss: 1.9320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "  'name' : 'part_A_question2',\n",
        "  'method': 'bayes',\n",
        "  'metric': {'goal': 'maximize', 'name': 'Val_Accuracy'},\n",
        "  'parameters': {'num_filters': {'values': [16, 32]},\n",
        "                  'filter_organisation': {'values': ['same','double','half']},\n",
        "                  'dropout_rate': {'values': [0.2, 0.5 , 0]},\n",
        "                  'filter_size': {'values': [3,5]},\n",
        "                  'num_neurons_dense': {'values': [128,512]},\n",
        "                  'activation': {'values': ['ReLU', 'GELU' , 'LeakyReLU' ]},\n",
        "                  'data_augmentation': {'values': ['True', 'False']},\n",
        "                  'batch_norm': {'values': ['True', 'False']},\n",
        "                  'epochs': {'values': [10 , 20]},\n",
        "\n",
        "              }}"
      ],
      "metadata": {
        "id": "1f20xGEoUfD7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sweep():\n",
        "    init_sweep =  wandb.init(project=\"CS6910_Assignment2\", name=\"part_A_question2\")\n",
        "    sweep_params = init_sweep.config\n",
        "\n",
        "    wandb.run.name = \"_nf_\" + str(sweep_params.num_filters) + \"_fo_\" + sweep_params.filter_organisation + \"_dr_\" + str(sweep_params.dropout_rate) + \"_neu_\" + str(sweep_params.num_neurons_dense) + \"_act_\" + sweep_params.activation +\"_aug_\" + sweep_params.data_augmentation +\"_norm_\" + sweep_params.batch_norm + \"_ep_\" + str(sweep_params.epochs)\n",
        "\n",
        "\n",
        "    filter_sizes=[] #filter k*k dimention for 5 layers\n",
        "    for i in range(5):\n",
        "      filter_sizes.append(sweep_params.filter_size)\n",
        "    print(filter_sizes)\n",
        "    data_augmentation=sweep_params.data_augmentation # data augmentation flag\n",
        "\n",
        "    activation_for_cov=sweep_params.activation\n",
        "    conv_activations=_activation_registry(activation_for_cov) # activation function for each of the 5 layers\n",
        "\n",
        "    activation_for_dense=sweep_params.activation\n",
        "    dense_activation=_activation_registry(activation_for_dense) # activation function for the dense layer\n",
        "    dropout_rate=sweep_params.dropout_rate\n",
        "    batch_norm=sweep_params.batch_norm\n",
        "    num_neurons_dense=sweep_params.num_neurons_dense\n",
        "\n",
        "    # set num_filters in each layer\n",
        "    num_of_filters=sweep_params.num_filters #num of filters in 1st layer\n",
        "    filter_organisation=sweep_params.filter_organisation # double , same , half\n",
        "    num_filters=_configure_filters(num_of_filters,filter_organisation,filter_sizes)\n",
        "    print(num_filters)\n",
        "\n",
        "    epochs=sweep_params.epochs\n",
        "\n",
        "    model = VisionCore(num_filters,\n",
        "                filter_sizes,\n",
        "                conv_activations,\n",
        "                dense_activation,\n",
        "                num_neurons_dense,\n",
        "                dropout_rate,\n",
        "                batch_norm\n",
        "                ).to(device)\n",
        "    print(model)\n",
        "    train_loader , val_loader , test_loader = configure_loaders(data_augmentation)\n",
        "\n",
        "    print_on=\"wandb\"\n",
        "\n",
        "    val_accuracy=train(epochs,model,train_loader,val_loader,print_on)\n",
        "    wandb.log({\"Val_Accuracy\": val_accuracy})\n"
      ],
      "metadata": {
        "id": "9GUG87B3UfGZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project='CS6910_Assignment2_test')\n",
        "wandb.agent(sweep_id, train_sweep,count=50)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T1bpBRPBUfKO",
        "outputId": "f502d177-3cec-470a-deaa-001411e50717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: jb4xxojs\n",
            "Sweep URL: https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/sweeps/jb4xxojs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: coi93hm5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organisation: double\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_size: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons_dense: 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'CS6910_Assignment2' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250414_110834-coi93hm5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/runs/coi93hm5' target=\"_blank\">part_A_question2</a></strong> to <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/sweeps/jb4xxojs' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/sweeps/jb4xxojs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/sweeps/jb4xxojs' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/sweeps/jb4xxojs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/runs/coi93hm5' target=\"_blank\">https://wandb.ai/cs24m035-indian-institute-of-technology-madras/CS6910_Assignment2_test/runs/coi93hm5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 5, 5, 5, 5]\n",
            "[32, 64, 128, 256, 512]\n",
            "VisionCore(\n",
            "  (feature_engine): ModuleList(\n",
            "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Identity()\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (5): Identity()\n",
            "    (6): GELU(approximate='none')\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (9): Identity()\n",
            "    (10): GELU(approximate='none')\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (13): Identity()\n",
            "    (14): GELU(approximate='none')\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (17): Identity()\n",
            "    (18): GELU(approximate='none')\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0, inplace=False)\n",
            "    (1): Linear(in_features=4608, out_features=128, bias=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cycle [1/20], Batch [25/125]\n",
            "Cycle [1/20], Batch [50/125]\n",
            "Cycle [1/20], Batch [75/125]\n",
            "Cycle [1/20], Batch [100/125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AdQ7uV13Z9Bd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}